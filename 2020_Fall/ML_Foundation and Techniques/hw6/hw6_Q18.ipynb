{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_OOB = 0.07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "\n",
    "def main():\n",
    "\n",
    "    train_path = 'https://www.csie.ntu.edu.tw/~htlin/course/ml20fall/hw6/hw6_train.dat'\n",
    "    test_path = 'https://www.csie.ntu.edu.tw/~htlin/course/ml20fall/hw6/hw6_test.dat'\n",
    "\n",
    "    df_train = pd.read_csv(train_path, header=None, sep=' ').to_numpy()\n",
    "    df_test = pd.read_csv(test_path, header=None, sep=' ').to_numpy()\n",
    "    \n",
    "\n",
    "    X_train = df_train[:, :-1]\n",
    "    y_train = df_train[:, -1]\n",
    "    X_test = df_test[:,:-1]\n",
    "    y_test = df_test[:,-1]\n",
    "    \n",
    "    sample_size = 0.5\n",
    "    n_trees = 2000\n",
    "    trees = list()\n",
    "    y_OOB_pred = list()\n",
    "\n",
    "    \n",
    "    global OOB\n",
    "    OOB = np.zeros([len(df_train), n_trees])\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        X_sample, y_sample = subsample(df_train, sample_size, i)\n",
    "        tree = train(X_sample, y_sample)\n",
    "        trees.append(tree)\n",
    "        \n",
    "        \n",
    "    for x,i in zip(X_train, range(len(X_train))):\n",
    "        T = np.array(trees)\n",
    "        G_ = T[np.where(OOB[i] == 0)]\n",
    "        if len(G_) != 0:\n",
    "            predictions = [predict(tree, x) for tree in G_]\n",
    "            pred = max(set(predictions), key=predictions.count)\n",
    "            y_OOB_pred.append(pred)\n",
    "        else:\n",
    "            y_OOB_pred.append(-1)\n",
    "    \n",
    "    E_OOB = sum(y_OOB_pred != y_train) / float(len(y_train))\n",
    "\n",
    "        \n",
    "    print('E_OOB =', E_OOB)\n",
    "\n",
    "def impurity(y):\n",
    "    #Gini\n",
    "    N = len(y)\n",
    "    \n",
    "    if N == 0:\n",
    "        return 1\n",
    "    \n",
    "    pos = (y == 1).sum() / N\n",
    "    neg = (y == -1).sum() / N\n",
    "    \n",
    "    return (1 - (pos**2 + neg**2))\n",
    "\n",
    "def loss(X, y, theta):\n",
    "    y1 = y[X < theta]\n",
    "    y2 = y[X >= theta]\n",
    "    return len(y1) * impurity(y1) + len(y2) * impurity(y2)\n",
    "\n",
    "def get_theta(X):\n",
    "    X = np.sort(X)\n",
    "    theta = ((X[:-1] + X[1:]) / 2)\n",
    "    theta = np.r_[X[0] - 1, theta,  X[-1] + 1]\n",
    "    \n",
    "    return theta\n",
    "\n",
    "def dStump(X,y):\n",
    "    n, d = X.shape\n",
    "    \n",
    "    theta_best = 0\n",
    "    feature = 0\n",
    "    b_best = float('inf')\n",
    "    \n",
    "    for i in range(d):\n",
    "        x = X[:,i]\n",
    "        thetaList = get_theta(x)\n",
    "        for theta in thetaList:\n",
    "            b = loss(x,y,theta)\n",
    "            if b < b_best:\n",
    "                b_best = b\n",
    "                feature = i\n",
    "                theta_best = theta\n",
    "    \n",
    "    return feature, theta_best, b_best \n",
    "\n",
    "def terminate(X, y):\n",
    "    # all X are the same or all y are the same\n",
    "    condition1 = (X[0] == X).all()\n",
    "    condition2 = impurity(y) == 0\n",
    "    result = condition1 | condition2\n",
    "    return result\n",
    "\n",
    "class Dtree:\n",
    "    def __init__(self, theta, feature, value=None):\n",
    "        self.theta = theta\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "\n",
    "def train(X,y):\n",
    "    if terminate(X,y):\n",
    "        return Dtree(None, None, y[0])\n",
    "    else:\n",
    "        feature, theta, b_best = dStump(X,y)\n",
    "        tree = Dtree(theta, feature)\n",
    "        cut1 = X[:,feature] < theta\n",
    "        X1 = X[cut1]\n",
    "        y1 = y[cut1]\n",
    "        cut2 = X[:,feature] >= theta\n",
    "        X2 = X[cut2]\n",
    "        y2 = y[cut2]\n",
    "        left = train(X1,y1)\n",
    "        right = train(X2,y2)\n",
    "        tree.left = left\n",
    "        tree.right = right\n",
    "        \n",
    "        return tree\n",
    "\n",
    "def predict(tree, X):\n",
    "    if tree.value != None:\n",
    "        return tree.value\n",
    "    if X[tree.feature] < tree.theta:\n",
    "        return predict(tree.left, X)\n",
    "    else:\n",
    "        return predict(tree.right, X)\n",
    "\n",
    "\n",
    "def error(tree, X, y):\n",
    "    N = len(y)\n",
    "    y_pred = []\n",
    "    for i in X:\n",
    "        y_pred.append(predict(tree,i))\n",
    "    \n",
    "    return sum(y_pred != y)/ float(N)\n",
    "\n",
    "\n",
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(data, ratio, t):\n",
    "    n_sample = round(len(data) * ratio)\n",
    "    sample = np.empty([500,11])\n",
    "    global OOB\n",
    "    \n",
    "    for i in range(n_sample):\n",
    "        index = randrange(len(data))\n",
    "        OOB[index,t] += 1\n",
    "        sample[i] = data[index]\n",
    "    X = sample[:,:-1]\n",
    "    y = sample[:,-1]\n",
    "    return X, y\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
